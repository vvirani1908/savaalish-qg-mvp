{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af7b971",
   "metadata": {},
   "source": [
    "\n",
    "# Scalable Question Generation (MVP)\n",
    "**Author:** Vansh Virani  \n",
    "\n",
    "This notebook implements a minimal yet scalable pipeline to generate conceptual multiple-choice questions from large PDFs or text files, drawing inspiration from the Savaal paper's concept-driven RAG approach.\n",
    "\n",
    "Deliverables produced by this notebook:\n",
    "- A single JSON file at `output/questions.json` with all generated questions + metadata.\n",
    "- Clear, well-commented cells explaining design choices.\n",
    "\n",
    "Note: You will need API access to your chosen LLM and embedding model (default prompts assume Gemini). No secrets are stored in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78523f08",
   "metadata": {},
   "source": [
    "\n",
    "## Quickstart (Checklist)\n",
    "1. Install deps (next cell).  \n",
    "2. Set environment variables (API key) in the Config cell.  \n",
    "3. Put your input documents into the `docs/` folder (PDF or .txt).  \n",
    "4. Run all cells up to \"Generate Questions\".  \n",
    "5. Inspect and optionally filter by quality.  \n",
    "6. Find your final JSON at `output/questions.json`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829286d",
   "metadata": {},
   "source": [
    "## 0) Install once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65ad872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pypdf tiktoken faiss-cpu numpy pandas python-dotenv tqdm rapidfuzz google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f9cf4",
   "metadata": {},
   "source": [
    "\n",
    "## Config\n",
    "- We use **Gemini** for both chat and embeddings via `google-generativeai`.\n",
    "- API keys are read from `.env` (not committed).\n",
    "- Adjust `MAX_QUESTIONS`, `K_CONTEXT`, and `QUALITY_THRESHOLD` for speed/cost vs. quality.\n",
    "- Files go in `./docs/`; results in `./output/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e6cf1766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: gemini-1.5-flash | Embedding: text-embedding-004\n",
      "DOCS_DIR: /Users/vanshvirani/projects/savaalish-qg-mvp/docs\n",
      "OUTPUT_DIR: /Users/vanshvirani/projects/savaalish-qg-mvp/output\n",
      "MAX_QUESTIONS: 20 | K_CONTEXT: 3 | QUALITY_THRESHOLD: 0.7\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, math, time, datetime, uuid, logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from pypdf import PdfReader\n",
    "import tiktoken\n",
    "import faiss\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.ERROR)\n",
    "\n",
    "if Path(\".env\").exists():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY   = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "GEMINI_MODEL     = os.getenv(\"GEMINI_MODEL\", \"gemini-1.5-flash\")\n",
    "GEMINI_EMBEDDING = os.getenv(\"GEMINI_EMBEDDING\", \"text-embedding-004\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"Set GOOGLE_API_KEY in your .env before running generation.\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "ROOT = Path().resolve()\n",
    "DOCS_DIR = ROOT / \"docs\"\n",
    "OUTPUT_DIR = ROOT / \"output\"\n",
    "DOCS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Model:\", GEMINI_MODEL, \"| Embedding:\", GEMINI_EMBEDDING)\n",
    "print(\"DOCS_DIR:\", DOCS_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "\n",
    "MAX_QUESTIONS = int(os.getenv(\"MAX_QUESTIONS\", \"12\"))\n",
    "K_CONTEXT     = int(os.getenv(\"K_CONTEXT\", \"2\"))\n",
    "QUALITY_THRESHOLD = float(os.getenv(\"QUALITY_THRESHOLD\", \"0.65\"))\n",
    "CHUNK_SIZE    = int(os.getenv(\"CHUNK_SIZE\", \"900\"))\n",
    "CHUNK_OVERLAP = int(os.getenv(\"CHUNK_OVERLAP\", \"150\"))\n",
    "\n",
    "print(\"MAX_QUESTIONS:\", MAX_QUESTIONS, \"| K_CONTEXT:\", K_CONTEXT, \"| QUALITY_THRESHOLD:\", QUALITY_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd48063",
   "metadata": {},
   "source": [
    "\n",
    "## Utilities — chunking and document loading\n",
    "\n",
    "- We **chunk** long text with token overlap (to avoid cutting concepts in half).  \n",
    "- The loader reads PDFs with `pypdf`, then falls back to **PyMuPDF** if needed (helps with tricky layouts).  \n",
    "- Image‑only PDFs will need OCR; for this MVP, we skip those or you can add a `.txt` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b24fd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def chunk_text(text: str, max_tokens=800, overlap=120) -> List[str]:\n",
    "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    toks = enc.encode(text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    while i < len(toks):\n",
    "        sub = toks[i: i + max_tokens]\n",
    "        chunks.append(enc.decode(sub))\n",
    "        i += max_tokens - overlap\n",
    "    return chunks\n",
    "\n",
    "def load_docs(docs_dir: Path) -> List[Tuple[str, str]]:\n",
    "    docs = []\n",
    "    for p in docs_dir.glob(\"**/*\"):\n",
    "        if p.is_dir():\n",
    "            continue\n",
    "\n",
    "        if p.suffix.lower() == \".pdf\":\n",
    "            text = \"\"\n",
    "            try:\n",
    "                if p.stat().st_size < 1024:\n",
    "                    print(f\" Skipping {p.name}: too small/empty ({p.stat().st_size} bytes).\")\n",
    "                    continue\n",
    "                reader = PdfReader(str(p))\n",
    "                pages = [page.extract_text() or \"\" for page in reader.pages]\n",
    "                text = \"\\n\".join(pages).strip()\n",
    "            except Exception as e:\n",
    "                print(f\" pypdf issue on {p.name}: {e}\")\n",
    "                text = \"\"\n",
    "\n",
    "            if not text:\n",
    "                try:\n",
    "                    import fitz\n",
    "                    with fitz.open(str(p)) as doc:\n",
    "                        text = \"\\n\".join(page.get_text() for page in doc).strip()\n",
    "                except Exception as e:\n",
    "                    print(f\" PyMuPDF fallback failed for {p.name}: {e}\")\n",
    "                    text = \"\"\n",
    "\n",
    "            if text:\n",
    "                docs.append((str(p), text))\n",
    "            else:\n",
    "                print(f\" No extractable text in {p.name}; skip or add a .txt.\")\n",
    "\n",
    "        elif p.suffix.lower() == \".txt\":\n",
    "            try:\n",
    "                t = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
    "                if t:\n",
    "                    docs.append((str(p), t))\n",
    "                else:\n",
    "                    print(f\" Skipping empty txt: {p.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\" Skipping txt {p.name}: {e}\")\n",
    "    print(f\"Loaded {len(docs)} text-bearing document(s).\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fae45",
   "metadata": {},
   "source": [
    "\n",
    "## LLM helpers — Gemini wrappers and safe JSON parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3d7cc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(system: str, user: str, max_tokens=700, temperature=0.0, as_json=False) -> str:\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL, system_instruction=system)\n",
    "    gen_cfg = {\"temperature\": float(temperature), \"max_output_tokens\": int(max_tokens)}\n",
    "    if as_json:\n",
    "        gen_cfg[\"response_mime_type\"] = \"application/json\"\n",
    "    resp = model.generate_content(user, generation_config=gen_cfg)\n",
    "    return (resp.text or \"\").strip()\n",
    "\n",
    "def embed_texts(texts: List[str], batch: int = 64) -> np.ndarray:\n",
    "    vecs = []\n",
    "    for i in range(0, len(texts), batch):\n",
    "        for t in texts[i:i+batch]:\n",
    "            r = genai.embed_content(model=GEMINI_EMBEDDING, content=t, task_type=\"retrieval_document\")\n",
    "            vecs.append(r[\"embedding\"])\n",
    "    return np.array(vecs, dtype=\"float32\")\n",
    "\n",
    "import json, re\n",
    "def parse_json_loose(s: str):\n",
    "    if isinstance(s, (dict, list)):\n",
    "        return s\n",
    "    txt = (s or \"\").strip()\n",
    "    txt = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", txt, flags=re.S)\n",
    "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\", txt, flags=re.S)\n",
    "    if m:\n",
    "        block = m.group(1)\n",
    "        try:\n",
    "            return json.loads(block)\n",
    "        except Exception:\n",
    "            if '\"' not in block and \"'\" in block:\n",
    "                try:\n",
    "                    return json.loads(block.replace(\"'\", '\"'))\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return json.loads(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab83847",
   "metadata": {},
   "source": [
    "\n",
    "## Retrieval index and idea extraction\n",
    "We prompt the LLM to extract 1-3 conceptual ideas per chunk. Then we lightly merge near-duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "455166f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_faiss_index(chunks: List[str]):\n",
    "    embs = embed_texts(chunks)\n",
    "    faiss.normalize_L2(embs)\n",
    "    index = faiss.IndexFlatIP(embs.shape[1])\n",
    "    index.add(embs)\n",
    "    return index\n",
    "\n",
    "def retrieve_context_for_idea(idea_text: str, index, all_chunks: List[str], chunk_meta: List[Dict[str,Any]], k=3):\n",
    "    qvec = embed_texts([idea_text])\n",
    "    faiss.normalize_L2(qvec)\n",
    "    scores, idxs = index.search(qvec, k)\n",
    "    items = []\n",
    "    for rank, (j, sc) in enumerate(zip(idxs[0], scores[0]), 1):\n",
    "        items.append({\"rank\": rank, \"score\": float(sc), \"chunk\": all_chunks[j], \"meta\": chunk_meta[j]})\n",
    "    return items\n",
    "\n",
    "IDEA_SYSTEM = (\n",
    "    \"Extract conceptual ideas from academic/professional prose. \"\n",
    "    \"Return ONLY a JSON array; each item has keys: title (str), summary (str).\"\n",
    ")\n",
    "IDEA_USER_TMPL = (\n",
    "    \"Extract up to 3 non-trivial conceptual IDEAS (definitions, mechanisms, assumptions, trade-offs).\\n\"\n",
    "    \"TEXT:\\n---\\n{chunk}\\n---\\nReturn ONLY JSON.\"\n",
    ")\n",
    "\n",
    "def _normalize_idea_items(obj):\n",
    "    if isinstance(obj, str):\n",
    "        try: obj = json.loads(obj)\n",
    "        except Exception:\n",
    "            m = re.search(r\"\\[.*\\]\", obj, re.S)\n",
    "            obj = json.loads(m.group(0)) if m else []\n",
    "    if isinstance(obj, dict):\n",
    "        obj = obj.get(\"ideas\") or obj.get(\"items\") or obj.get(\"results\") or obj.get(\"data\") or obj.get(\"concepts\") or []\n",
    "    if not isinstance(obj, list):\n",
    "        obj = [obj]\n",
    "    out = []\n",
    "    for it in obj:\n",
    "        if isinstance(it, str):\n",
    "            t = it.strip()\n",
    "            if t: out.append({\"title\": t[:80], \"summary\": t})\n",
    "        elif isinstance(it, dict):\n",
    "            title = (it.get(\"title\") or it.get(\"idea\") or it.get(\"concept\") or it.get(\"name\") or \"\").strip()\n",
    "            summary = (it.get(\"summary\") or it.get(\"desc\") or it.get(\"explanation\") or \"\").strip()\n",
    "            if not title and summary: title = summary.split(\".\")[0][:80]\n",
    "            if not summary and title: summary = title\n",
    "            if title or summary: out.append({\"title\": title, \"summary\": summary})\n",
    "    return out\n",
    "\n",
    "def extract_ideas_per_chunk(chunks: List[str]) -> List[Dict[str,str]]:\n",
    "    ideas = []\n",
    "    for ch in chunks:\n",
    "        out = chat(IDEA_SYSTEM, IDEA_USER_TMPL.format(chunk=ch), max_tokens=400, as_json=True)\n",
    "        ideas.extend(_normalize_idea_items(out))\n",
    "    return ideas\n",
    "\n",
    "def dedup_ideas(ideas: List[Dict[str,str]], thresh=88) -> List[Dict[str,str]]:\n",
    "    kept = []\n",
    "    for idea in ideas:\n",
    "        if not any(fuzz.token_set_ratio(idea[\"title\"], k[\"title\"]) >= thresh for k in kept):\n",
    "            kept.append(idea)\n",
    "    for i, it in enumerate(kept):\n",
    "        it[\"id\"] = f\"idea_{i+1:04d}\"\n",
    "    return kept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f1309",
   "metadata": {},
   "source": [
    "\n",
    "## Question generation, scoring, difficulty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "67cb1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QG_SYSTEM = (\n",
    "    \"You write exam-quality multiple-choice questions that test conceptual understanding.\\n\"\n",
    "    \"- 1 question only, grounded in the given context.\\n\"\n",
    "    \"- 4 options (A-D), exactly one correct.\\n\"\n",
    "    \"- Avoid trivial recall and ambiguity.\\n\"\n",
    "    \"Return strict JSON: {\\\"question\\\": str, \\\"choices\\\": [{\\\"label\\\":\\\"A\\\",\\\"text\\\":...},...], \\\"correct_label\\\": \\\"A\\\"}\"\n",
    ")\n",
    "QG_USER_TMPL = \"Idea summary: {idea}\\nUse these supporting snippets to craft 1 conceptual question (avoid trivia):\\n{contexts}\\nReturn ONLY JSON.\"\n",
    "\n",
    "QC_SYSTEM = (\n",
    "    \"You are grading a multiple-choice question with rubric 0.0-1.0.\\n\"\n",
    "    \"Criteria: clarity, groundedness, non_triviality, distractor_quality.\\n\"\n",
    "    \"Return JSON: {\\\"clarity\\\":x,\\\"groundedness\\\":x,\\\"non_triviality\\\":x,\\\"distractor_quality\\\":x,\\\"notes\\\":str}\"\n",
    ")\n",
    "QC_TMPL = \"Question:\\n{q}\\nChoices:\\n{choices}\\nCorrect: {correct}\\nContext (evidence):\\n{ctx}\\n\"\n",
    "\n",
    "DIFF_SYSTEM = \"Classify the Bloom level (Remember/Understand/Apply/Analyze/Evaluate/Create). Return JSON: {\\\"bloom\\\":\\\"Understand\\\"}\"\n",
    "\n",
    "def shuffle_choices(payload: Dict[str,Any]) -> Dict[str,Any]:\n",
    "    choices = payload[\"choices\"]\n",
    "    correct = payload[\"correct_label\"]\n",
    "    correct_text = next(c[\"text\"] for c in choices if c[\"label\"] == correct)\n",
    "    import random\n",
    "    random.shuffle(choices)\n",
    "    labels = [\"A\",\"B\",\"C\",\"D\"]\n",
    "    out_choices, new_correct = [], None\n",
    "    for lab, ch in zip(labels, choices):\n",
    "        out_choices.append({\"label\": lab, \"text\": ch[\"text\"]})\n",
    "        if ch[\"text\"] == correct_text:\n",
    "            new_correct = lab\n",
    "    payload[\"choices\"] = out_choices\n",
    "    payload[\"correct_label\"] = new_correct\n",
    "    return payload\n",
    "\n",
    "def generate_question_for_idea(idea: Dict[str,Any], index, all_chunks, chunk_meta, k=2) -> Dict[str,Any]:\n",
    "    ctx_items = retrieve_context_for_idea(idea[\"summary\"], index, all_chunks, chunk_meta, k=k)\n",
    "    ctx_str = \"\\n---\\n\".join([it[\"chunk\"][:1200] for it in ctx_items])\n",
    "    out = chat(QG_SYSTEM, QG_USER_TMPL.format(idea=idea[\"summary\"], contexts=ctx_str), max_tokens=700, as_json=True)\n",
    "    data = parse_json_loose(out)\n",
    "    data = shuffle_choices(data)\n",
    "    data[\"id\"] = idea[\"id\"]\n",
    "    data[\"idea_summary\"] = idea[\"summary\"]\n",
    "    data[\"source_citations\"] = [f\"{it['meta']['doc']}|{it['meta']['chunk_id']}\" for it in ctx_items]\n",
    "    return data\n",
    "\n",
    "def score_question(item: Dict[str,Any]) -> Dict[str,Any]:\n",
    "    q = item[\"question\"]\n",
    "    ch = \"\\n\".join([f\"{c['label']}) {c['text']}\" for c in item[\"choices\"]])\n",
    "    ctx = \"\\n---\\n\".join(item[\"source_citations\"])\n",
    "    out = chat(QC_SYSTEM, QC_TMPL.format(q=q, choices=ch, correct=item[\"correct_label\"], ctx=ctx), max_tokens=400, as_json=True)\n",
    "    scores = parse_json_loose(out)\n",
    "    import numpy as np\n",
    "    overall = float(np.mean([scores.get(\"clarity\",0), scores.get(\"groundedness\",0), scores.get(\"non_triviality\",0), scores.get(\"distractor_quality\",0)]))\n",
    "    item[\"quality\"] = {\n",
    "        \"overall\": round(overall,3),\n",
    "        \"clarity\": round(float(scores.get(\"clarity\",0)),3),\n",
    "        \"groundedness\": round(float(scores.get(\"groundedness\",0)),3),\n",
    "        \"non_triviality\": round(float(scores.get(\"non_triviality\",0)),3),\n",
    "        \"distractor_quality\": round(float(scores.get(\"distractor_quality\",0)),3),\n",
    "        \"notes\": scores.get(\"notes\",\"\"),\n",
    "    }\n",
    "    return item\n",
    "\n",
    "def add_difficulty(item: Dict[str,Any]) -> Dict[str,Any]:\n",
    "    text = item[\"question\"] + \" Choices: \" + \"; \".join([c[\"text\"] for c in item[\"choices\"]])\n",
    "    out = chat(DIFF_SYSTEM, text, max_tokens=80, as_json=True)\n",
    "    try:\n",
    "        bloom = parse_json_loose(out).get(\"bloom\",\"Understand\")\n",
    "    except Exception:\n",
    "        bloom = \"Understand\"\n",
    "    mapping = {\"Remember\":\"easy\",\"Understand\":\"easy\",\"Apply\":\"medium\",\"Analyze\":\"medium\",\"Evaluate\":\"hard\",\"Create\":\"hard\"}\n",
    "    item[\"difficulty\"] = mapping.get(bloom, \"medium\")\n",
    "    return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966fa9e",
   "metadata": {},
   "source": [
    "\n",
    "## Accuracy proxy (judge) and coverage tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3cf692fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JUDGE_SYSTEM = (\n",
    "    \"You are a strict exam proctor. Given a question, options, and evidence, \"\n",
    "    \"select the single correct label A-D. If evidence is insufficient, return 'U'. \"\n",
    "    \"Return ONLY JSON: {\\\"label\\\":\\\"A|B|C|D|U\\\",\\\"justification\\\":str}\"\n",
    ")\n",
    "JUDGE_TMPL = \"\"\"Question:\n",
    "{q}\n",
    "\n",
    "Choices:\n",
    "{choices}\n",
    "\n",
    "Evidence:\n",
    "{ctx}\n",
    "\"\"\"\n",
    "\n",
    "def judge_label(qitem):\n",
    "    ch = \"\\n\".join([f\"{c['label']}) {c['text']}\" for c in qitem[\"choices\"]])\n",
    "    ctx = \"\\n---\\n\".join(qitem[\"source_citations\"])\n",
    "    out = chat(JUDGE_SYSTEM, JUDGE_TMPL.format(q=qitem[\"question\"], choices=ch, ctx=ctx), max_tokens=200, temperature=0.0, as_json=True)\n",
    "    data = parse_json_loose(out)\n",
    "    return (data.get(\"label\") or \"U\").strip(), data.get(\"justification\",\"\" )\n",
    "\n",
    "def cited_chunk_ids(item):\n",
    "    ids = []\n",
    "    for c in item[\"source_citations\"]:\n",
    "        m = re.search(r\"#chunk(\\d+)\", c)\n",
    "        if m: ids.append(int(m.group(1)))\n",
    "    return ids\n",
    "\n",
    "def coverage_report(results, all_chunks):\n",
    "    used = set()\n",
    "    for it in results:\n",
    "        used.update(cited_chunk_ids(it))\n",
    "    ratio = (len(used) / len(all_chunks)) if all_chunks else 0.0\n",
    "    print(f\"Chunk coverage: {len(used)}/{len(all_chunks)} = {ratio:.1%}\")\n",
    "    return ratio\n",
    "\n",
    "def primary_chunk_for_idea(idea, index, all_chunks, chunk_meta, k=1):\n",
    "    ctx = retrieve_context_for_idea(idea[\"summary\"], index, all_chunks, chunk_meta, k=k)\n",
    "    if not ctx: return None\n",
    "    m = re.search(r\"#chunk(\\d+)\", ctx[0][\"meta\"][\"chunk_id\"])\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def stratified_select(ideas, index, all_chunks, chunk_meta, num_questions, bins=10):\n",
    "    mapped = []\n",
    "    for it in ideas:\n",
    "        idx = primary_chunk_for_idea(it, index, all_chunks, chunk_meta, k=1)\n",
    "        if idx is not None:\n",
    "            mapped.append((idx, it))\n",
    "    if not mapped:\n",
    "        return ideas[:num_questions]\n",
    "\n",
    "    max_idx = max(idx for idx,_ in mapped) + 1\n",
    "    bin_size = max(1, math.ceil(max_idx / bins))\n",
    "    buckets = [[] for _ in range(bins)]\n",
    "    for idx, it in mapped:\n",
    "        b = min(idx // bin_size, bins-1)\n",
    "        buckets[b].append(it)\n",
    "\n",
    "    out = []\n",
    "    while len(out) < num_questions and any(buckets):\n",
    "        for b in buckets:\n",
    "            if b and len(out) < num_questions:\n",
    "                out.append(b.pop(0))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c822d51",
   "metadata": {},
   "source": [
    "\n",
    "## Run the pipeline (end‑to‑end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fdedf5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 text-bearing document(s).\n",
      "Loaded 1 document(s).\n",
      "Total chunks: 147\n",
      "Extracting ideas...\n",
      "Ideas found: 281\n",
      "Selected ideas: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Qs: 100%|██████████| 20/20 [01:07<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: 20  /  Kept after quality filter (>= 0.7): 20\n",
      "Judge agreement: 17/19 = 89.47%  (unknown=0)\n",
      "Chunk coverage: 52/147 = 35.4%\n",
      "Saved -> /Users/vanshvirani/projects/savaalish-qg-mvp/output/questions.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = load_docs(DOCS_DIR)\n",
    "docs_names = [d[0] for d in docs]\n",
    "print(f\"Loaded {len(docs)} document(s).\") \n",
    "\n",
    "all_chunks, chunk_meta = [], []\n",
    "for path, text in docs:\n",
    "    chunks = chunk_text(text, max_tokens=CHUNK_SIZE, overlap=CHUNK_OVERLAP)\n",
    "    for idx, ch in enumerate(chunks):\n",
    "        all_chunks.append(ch)\n",
    "        chunk_meta.append({\"doc\": path, \"chunk_id\": f\"{path}#chunk{idx}\"})\n",
    "print(f\"Total chunks: {len(all_chunks)}\") \n",
    "\n",
    "if not all_chunks:\n",
    "    raise SystemExit(\"No text to process. Add PDFs/.txt into ./docs and re-run.\")\n",
    "\n",
    "index = build_faiss_index(all_chunks)\n",
    "\n",
    "print(\"Extracting ideas...\")\n",
    "ideas_raw = extract_ideas_per_chunk(all_chunks)\n",
    "ideas = dedup_ideas(ideas_raw, thresh=88)\n",
    "print(\"Ideas found:\", len(ideas))\n",
    "\n",
    "selected_ideas = stratified_select(\n",
    "    ideas, index, all_chunks, chunk_meta, num_questions=MAX_QUESTIONS, bins=10\n",
    ")\n",
    "print(\"Selected ideas:\", len(selected_ideas))\n",
    "\n",
    "results = []\n",
    "for idea in tqdm(selected_ideas, desc=\"Generating Qs\"):\n",
    "    try:\n",
    "        item = generate_question_for_idea(idea, index, all_chunks, chunk_meta, k=K_CONTEXT)\n",
    "        item = score_question(item)\n",
    "        item = add_difficulty(item)\n",
    "        results.append(item)\n",
    "    except Exception as e:\n",
    "        print(f\"!! Skipping {idea.get('id')} due to parse error: {e}\")\n",
    "        continue\n",
    "\n",
    "filtered = [r for r in results if r.get(\"quality\",{}).get(\"overall\",0) >= QUALITY_THRESHOLD]\n",
    "print(f\"Generated: {len(results)}  /  Kept after quality filter (>= {QUALITY_THRESHOLD}): {len(filtered)}\") \n",
    "\n",
    "agree, unknown, total = 0, 0, 0\n",
    "for it in filtered:\n",
    "    try:\n",
    "        lab, _ = judge_label(it)\n",
    "        if lab == \"U\": unknown += 1\n",
    "        else:\n",
    "            total += 1\n",
    "            if lab == it[\"correct_label\"]: agree += 1\n",
    "    except Exception:\n",
    "        pass\n",
    "if total:\n",
    "    print(f\"Judge agreement: {agree}/{total} = {agree/total:.2%}  (unknown={unknown})\")\n",
    "else:\n",
    "    print(\"Judge skipped (no items or all unknown).\") \n",
    "\n",
    "coverage_report(filtered, all_chunks)\n",
    "\n",
    "out = {\n",
    "    \"run_metadata\": {\n",
    "        \"created_at\": datetime.datetime.now().isoformat(),\n",
    "        \"docs\": docs_names,\n",
    "        \"model\": GEMINI_MODEL,\n",
    "        \"embedding_model\": GEMINI_EMBEDDING,\n",
    "        \"k_context\": K_CONTEXT,\n",
    "        \"quality_threshold\": QUALITY_THRESHOLD,\n",
    "    },\n",
    "    \"questions\": filtered,\n",
    "}\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "with open(OUTPUT_DIR / \"questions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(out, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved ->\", OUTPUT_DIR / \"questions.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c26dab5",
   "metadata": {},
   "source": [
    "\n",
    "## Peek at the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f201bdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 20\n",
      "{'choices': [{'label': 'A',\n",
      "              'text': 'It primarily serves as a mathematical curiosity, with '\n",
      "                      'limited practical applications in engineering or '\n",
      "                      'physics.'},\n",
      "             {'label': 'B',\n",
      "              'text': 'It proves the existence of complex numbers, resolving a '\n",
      "                      'long-standing mathematical debate about their '\n",
      "                      'validity.'},\n",
      "             {'label': 'C',\n",
      "              'text': 'It facilitates conversions between Cartesian, polar, '\n",
      "                      'and exponential forms, enabling easier calculations and '\n",
      "                      'geometric interpretations of complex number '\n",
      "                      'operations.'},\n",
      "             {'label': 'D',\n",
      "              'text': 'It simplifies complex number arithmetic by providing a '\n",
      "                      'single, unified representation, eliminating the need '\n",
      "                      'for conversions between forms.'}],\n",
      " 'correct_label': 'C',\n",
      " 'difficulty': 'easy',\n",
      " 'id': 'idea_0001',\n",
      " 'idea_summary': 'Complex numbers are represented in Cartesian, polar, or '\n",
      "                 'exponential forms, each offering different insights into '\n",
      "                 \"their magnitude and phase.  Euler's formula connects these \"\n",
      "                 'representations, facilitating calculations and geometric '\n",
      "                 'interpretations of arithmetic operations.',\n",
      " 'quality': {'clarity': 1.0,\n",
      "             'distractor_quality': 0.9,\n",
      "             'groundedness': 1.0,\n",
      "             'non_triviality': 0.8,\n",
      "             'notes': 'The question and its correct answer are well-defined.  '\n",
      "                      'The distractors are plausible but incorrect, making '\n",
      "                      'them good distractors. The non-triviality score is '\n",
      "                      \"slightly lower because Euler's formula is a fundamental \"\n",
      "                      'concept, and its significance is relatively '\n",
      "                      'straightforward for those familiar with complex '\n",
      "                      'numbers.  The question could be improved by increasing '\n",
      "                      'the difficulty, perhaps by including more nuanced '\n",
      "                      \"aspects of Euler's formula or its applications.\",\n",
      "             'overall': 0.925},\n",
      " 'question': 'A complex number z can be represented in Cartesian form as x + '\n",
      "             'jy, polar form as rcos(ϖ) + jrsin(ϖ), and exponential form as '\n",
      "             \"re<sup>jϖ</sup>.  Euler's formula establishes the connection \"\n",
      "             'between these forms.  Which statement BEST captures the '\n",
      "             \"significance of Euler's formula in this context?\",\n",
      " 'source_citations': ['/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf|/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf#chunk7',\n",
      "                      '/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf|/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf#chunk6',\n",
      "                      '/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf|/Users/vanshvirani/projects/savaalish-qg-mvp/docs/notes.pdf#chunk5']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "p = OUTPUT_DIR / \"questions.json\"\n",
    "if p.exists():\n",
    "    data = json.loads(p.read_text())\n",
    "    print(\"Total questions:\", len(data.get(\"questions\", [])))\n",
    "    if data.get(\"questions\"):\n",
    "        from pprint import pprint\n",
    "        pprint(data[\"questions\"][0])\n",
    "else:\n",
    "    print(\"questions.json not found (run the previous cell).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9523d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
